import os
import time
import re
import requests
import random
import logging
import threading
import queue
import uuid
import concurrent.futures
from datetime import datetime, timedelta
import striprtf.striprtf as striprtf
from django.conf import settings
from django.utils import timezone
from django.db import models
from bankruptcy.models import TrackedCourtDecision


class FastResolutionExtractor:
    """
    –í–∏—Å–æ–∫–æ–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ SR_AI
    """
    
    def __init__(self):
        # üöÄ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–ò–í–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –î–õ–Ø –®–í–ò–î–ö–û–î–Ü–á
        self.max_workers = getattr(settings, "RESOLUTION_MAX_WORKERS", 15)  # –£–õ–¨–¢–†–ê: 15 –ø–æ—Ç–æ–∫—ñ–≤ –¥–ª—è —É–ª—å—Ç—Ä–∞ —à–≤–∏–¥–∫–æ—Å—Ç—ñ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è
        self.batch_size = getattr(settings, "RESOLUTION_BATCH_SIZE", 1000)  # –ö–†–ò–¢–ò–ß–ù–û: –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 1000 –∑–∞ —Ä–∞–∑
        self.download_timeout = getattr(settings, "RESOLUTION_DOWNLOAD_TIMEOUT", 15)  # –°–∫–æ—Ä–æ—á–µ–Ω–æ –¥–æ 15 —Å–µ–∫—É–Ω–¥
        self.temp_dir = getattr(settings, "TEMP_DIR", "/tmp/resolution_temp")
        self.request_delay = getattr(settings, "REQUEST_DELAY", 0.01)  # –ö–†–ò–¢–ò–ß–ù–û: –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ 0.01—Å
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
        os.makedirs(self.temp_dir, exist_ok=True)
        
        # üöÄ –ê–ì–†–ï–°–ò–í–ù–Ü –ü–ê–†–ê–ú–ï–¢–†–ò –ö–ï–®–£–í–ê–ù–ù–Ø –î–õ–Ø –®–í–ò–î–ö–û–î–Ü–á
        self.preload_queue = queue.Queue(maxsize=1000)  # –ó–ë–Ü–õ–¨–®–ï–ù–û –¥–æ 1000 
        self.preload_thread = None
        self.stop_preload_event = threading.Event()
        
        # –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø—É –¥–æ —Ñ–∞–π–ª—ñ–≤
        self.file_locks = {}
        self.lock_for_locks = threading.Lock()
        
        # üöÄ –†–û–ó–®–ò–†–ï–ù–ò–ô –ö–ï–® –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–á –®–í–ò–î–ö–û–î–Ü–á
        self.document_cache = {}  # –ö–µ—à –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
        self.url_cache = {}       # –ö–µ—à URL –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
        self.session_pool = {}    # –ü—É–ª —Å–µ—Å—ñ–π –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
        
        # –ü–∞—Ç–µ—Ä–Ω–∏ –¥–ª—è –ø–æ—à—É–∫—É —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¢–û–ß–ù–û —Ç—ñ –∂ –ø–∞—Ç–µ—Ä–Ω–∏ —â–æ –≤ SR_AI - –ø—Ä–æ—Å—Ç–∞, –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ —Å–∏—Å—Ç–µ–º–∞
        self.resolution_patterns = [
            r"–£–•–í–ê–õ–ò–í:(.*)",
            r"–£–•–í–ê–õ–ò–í :(.*)",
            r"–£ –• –í –ê –õ –ò –í :(.*)",
            r"–£ –• –í –ê –õ –ò –í(.*)",
            r"–£ –• –í –ê –õ –ò –í:(.*)",
            r"–ü–û–°–¢–ê–ù–û–í–ò–í:(.*)",
            r"–ü–û–°–¢–ê–ù–û–í–ò–í :(.*)",
            r"–ü –û –° –¢ –ê –ù –û –í –ò –í :(.*)",
            r"–ü –û –° –¢ –ê –ù –û –í –ò –í(.*)",
            r"–ü –û –° –¢ –ê –ù –û –í –ò –í:(.*)",
            r"–í–ò–†–Ü–®–ò–í:(.*)",
            r"–í–ò–†–Ü–®–ò–í :(.*)",
            r"–í –ò –† –Ü –® –ò –í :(.*)",
            r"–í –ò –† –Ü –® –ò –í:(.*)",
            # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –ø–æ–∫—Ä–∏—Ç—Ç—è
            r"–ü–û–°–¢–ê–ù–û–í–ò–õ[–ê–ò]?:(.*)",
            r"–†–Ü–®–ò–í:(.*)",
        ]
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
        self.setup_logging()
    
    def setup_logging(self):
        """–ù–∞–ª–∞—à—Ç–æ–≤—É—î –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è —Å–µ—Ä–≤—ñ—Å—É"""
        log_dir = os.path.join(settings.BASE_DIR, "logs")
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, f"resolution_extractor_{datetime.now().strftime("%Y%m%d")}.log")
        
        self.logger = logging.getLogger("fast_resolution_extractor")
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers:
            handler = logging.FileHandler(log_file, encoding="utf-8")
            formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def start_preloading(self, decisions):
        """
        –ó–∞–ø—É—Å–∫–∞—î —Ñ–æ–Ω–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
        """
        if not decisions:
            return
            
        def preload_worker():
            for decision in decisions:
                if self.stop_preload_event.is_set():
                    break
                    
                if decision.doc_url and decision.doc_url.startswith("http"):
                    try:
                        file_path = self.download_document(decision.doc_url, str(decision.id))
                        if file_path:
                            self.preload_queue.put((decision.id, file_path), block=False)
                    except queue.Full:
                        pass
                    except Exception as e:
                        self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–º—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è {decision.id}: {e}")
        
        self.stop_preload_event.clear()
        self.preload_thread = threading.Thread(target=preload_worker)
        self.preload_thread.daemon = True
        self.preload_thread.start()
        print(f"–ó–∞–ø—É—â–µ–Ω–æ —Ñ–æ–Ω–æ–≤–µ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤...")
    
    def stop_preloading(self):
        """
        –ó—É–ø–∏–Ω—è—î –ø—Ä–æ—Ü–µ—Å –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        """
        if self.preload_thread and self.preload_thread.is_alive():
            self.stop_preload_event.set()
            self.preload_thread.join(timeout=1.0)
            print("–§–æ–Ω–æ–≤–µ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑—É–ø–∏–Ω–µ–Ω–æ.")
    
    def get_preloaded_document(self, decision_id):
        """
        –û—Ç—Ä–∏–º—É—î –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –∑ —á–µ—Ä–≥–∏
        """
        try:
            for _ in range(self.preload_queue.qsize()):
                doc_id, path = self.preload_queue.get(block=False)
                if doc_id == decision_id:
                    return path
                else:
                    self.preload_queue.put((doc_id, path), block=False)
        except (queue.Empty, Exception):
            pass
        
        return None
    
    def download_document(self, url, doc_id):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞ URL –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏
        """
        if not url or url == "nan":
            return None

        cache_key = f"{url}_{doc_id}"
        if cache_key in self.document_cache:
            return self.document_cache[cache_key]

        file_path = os.path.join(self.temp_dir, f"document_{doc_id}_{uuid.uuid4().hex[:8]}.rtf")
        
        time.sleep(self.request_delay + random.uniform(0, 0.005))  # üöÄ –ö–†–ò–¢–ò–ß–ù–û: –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤–∞ –∑–∞—Ç—Ä–∏–º–∫–∞
        
        max_retries = 5  # –ó–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 5 –∑–≥—ñ–¥–Ω–æ –∑ –µ—Ç–∞–ª–æ–Ω–Ω–∏–º –ø—Ä–æ–µ–∫—Ç–æ–º
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    delay = (2 ** attempt) + random.uniform(0, 1)
                    time.sleep(delay)
                    self.logger.info(f"–°–ø—Ä–æ–±–∞ #{attempt+1} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}")
                
                # üöÄ –ö–†–ò–¢–ò–ß–ù–û: –í–ò–ö–û–†–ò–°–¢–û–í–£–Ñ–ú–û –ü–£–õ –°–ï–°–Ü–ô –î–õ–Ø –®–í–ò–î–ö–û–î–Ü–á
                thread_id = threading.current_thread().ident
                if thread_id not in self.session_pool:
                    session = requests.Session()
                    session.trust_env = False
                    # üöÄ –û–ü–¢–ò–ú–Ü–ó–û–í–ê–ù–Ü –ó–ê–ì–û–õ–û–í–ö–ò –î–õ–Ø –®–í–ò–î–ö–û–°–¢–Ü
                    session.headers.update({
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                        "Accept": "application/rtf,*/*;q=0.8",
                        "Accept-Language": "uk-UA,uk;q=0.9",
                        "Connection": "keep-alive",
                    })
                    self.session_pool[thread_id] = session
                else:
                    session = self.session_pool[thread_id]
                
                response = session.get(url, timeout=self.download_timeout)
                response.raise_for_status()

                if not response.content:
                    raise Exception("–û—Ç—Ä–∏–º–∞–Ω–æ –ø–æ—Ä–æ–∂–Ω—ñ–π –≤–º—ñ—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞")

                with open(file_path, "wb") as f:
                    f.write(response.content)
                
                if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
                    raise Exception("–§–∞–π–ª –Ω–µ –±—É–ª–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ –∞–±–æ –≤—ñ–Ω –ø–æ—Ä–æ–∂–Ω—ñ–π")

                self.document_cache[cache_key] = file_path
                return file_path
                
            except requests.exceptions.Timeout:
                if attempt >= max_retries:
                    self.logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}")
                    break
                    
            except requests.exceptions.HTTPError as e:
                self.logger.error(f"HTTP –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}: {e}")
                break
                
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}: {e}")
                if attempt >= max_retries:
                    break
        
        return None
    
    def extract_resolution_text(self, file_path, decision_name=""):
        """
        –í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–æ—ó —á–∞—Å—Ç–∏–Ω–∏ –∑ RTF –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        if not file_path or not os.path.exists(file_path):
            return "–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç: —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"

        time.sleep(0.005)  # üöÄ –ö–†–ò–¢–ò–ß–ù–û: –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ

        try:
            rtf_text = None
            max_attempts = 1  # üöÄ –ö–†–ò–¢–ò–ß–ù–û: —Ç—ñ–ª—å–∫–∏ –æ–¥–Ω–∞ —Å–ø—Ä–æ–±–∞ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            
            for attempt in range(max_attempts):
                try:
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        rtf_text = f.read()
                    break
                except PermissionError as e:
                    if attempt < max_attempts - 1:
                        time.sleep(0.1)  # üöÄ –ö–†–ò–¢–ò–ß–ù–û: —Å–∫–æ—Ä–æ—á–µ–Ω–∞ –∑–∞—Ç—Ä–∏–º–∫–∞
                    else:
                        return f"–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ—Å—Ç—É–ø –¥–æ —Ñ–∞–π–ª—É: {str(e)}"

            if not rtf_text:
                return "–ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç: –ø–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É"

            # –ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–õ–ò–í–û: –û—á–∏—â—É—î–º–æ NUL bytes –ø–µ—Ä–µ–¥ –æ–±—Ä–æ–±–∫–æ—é (–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è PostgreSQL –ø–æ–º–∏–ª–æ–∫)
            rtf_text = rtf_text.replace("\x00", "")

            try:
                plain_text = striprtf.rtf_to_text(rtf_text)
            except Exception as rtf_error:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó RTF: {rtf_error}")
                plain_text = re.sub(r"\\[a-z0-9]+", " ", rtf_text)
                plain_text = re.sub(r"\{|\}|\\|\n", " ", plain_text)
                plain_text = re.sub(r"\s+", " ", plain_text)

            # –û—á–∏—â—É—î–º–æ NUL bytes –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É —Ç–∞–∫–æ–∂
            if plain_text:
                plain_text = plain_text.replace("\x00", "")

            # –ü–æ—à—É–∫ –∑–∞ –ø–∞—Ç–µ—Ä–Ω–∞–º–∏
            for pattern in self.resolution_patterns:
                matches = re.search(pattern, plain_text, re.DOTALL | re.IGNORECASE)
                if matches:
                    resolution_text = re.sub(r"\s+", " ", matches.group(1).strip())
                    # –§—ñ–Ω–∞–ª—å–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è NUL bytes
                    resolution_text = resolution_text.replace("\x00", "") 
                    return resolution_text

            return "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_path}: {e}")
            return f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏: {str(e)}"
        finally:
            self.try_safely_delete_file(file_path)
    
    def try_safely_delete_file(self, file_path, max_attempts=2):
        """
        –ë–µ–∑–ø–µ—á–Ω–æ –≤–∏–¥–∞–ª—è—î —Ñ–∞–π–ª –∑ –ø–æ–≤—Ç–æ—Ä–Ω–∏–º–∏ —Å–ø—Ä–æ–±–∞–º–∏
        """
        for attempt in range(max_attempts):
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    return True
            except Exception as e:
                if attempt < max_attempts - 1:
                    time.sleep(0.3)
                else:
                    self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–¥–∞–ª–∏—Ç–∏ —Ñ–∞–π–ª {file_path}: {e}")
                    return False
        return True
    
    def process_single_decision(self, decision):
        """
        –û–±—Ä–æ–±–ª—è—î –æ–¥–Ω–µ —Å—É–¥–æ–≤–µ —Ä—ñ—à–µ–Ω–Ω—è
        """
        try:
            if not decision.doc_url or not decision.doc_url.startswith("http"):
                decision.resolution_text = "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π"
                decision.resolution_extracted_at = timezone.now()
                decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
                return decision
            
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
            file_path = self.get_preloaded_document(decision.id)
            
            # –Ø–∫—â–æ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ —á–µ—Ä–∑—ñ, –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º
            if not file_path:
                unique_suffix = str(uuid.uuid4())[:8]
                file_path = self.download_document(decision.doc_url, f"{decision.id}_{unique_suffix}")
            
            if file_path:
                # –°—Ç–≤–æ—Ä—é—î–º–æ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è –¥–ª—è —Ñ–∞–π–ª—É
                with self.lock_for_locks:
                    if file_path not in self.file_locks:
                        self.file_locks[file_path] = threading.Lock()
                
                # –í–∏—Ç—è–≥—É—î–º–æ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—É —á–∞—Å—Ç–∏–Ω—É
                with self.file_locks[file_path]:
                    resolution_text = self.extract_resolution_text(file_path, "")
                    decision.resolution_text = resolution_text
                    decision.resolution_extracted_at = timezone.now()
                    
                    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ç—Ä–∏–≥–µ—Ä–Ω—ñ —Å–ª–æ–≤–∞ –ø—ñ—Å–ª—è –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
                    if resolution_text and not resolution_text.startswith("–ù–µ –≤–¥–∞–ª–æ—Å—è") and not resolution_text.startswith("–ü–æ–º–∏–ª–∫–∞"):
                        self.analyze_triggers(decision)
                
                # –í–∏–¥–∞–ª—è—î–º–æ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É
                with self.lock_for_locks:
                    if file_path in self.file_locks:
                        del self.file_locks[file_path]
            else:
                decision.resolution_text = "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç"
                decision.resolution_extracted_at = timezone.now()
            
            decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
            return decision
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ä—ñ—à–µ–Ω–Ω—è {decision.id}: {e}")
            decision.resolution_text = f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"
            decision.resolution_extracted_at = timezone.now()
            decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
            return decision
    
    def process_single_decision_enhanced(self, decision):
        """
        –ü–æ–∫—Ä–∞—â–µ–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Ä—ñ—à–µ–Ω–Ω—è –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
        (–ê–¥–∞–ø—Ç–æ–≤–∞–Ω–æ –∑ SR_AI –ø—ñ–¥—Ö–æ–¥—É)
        """
        try:
            if not decision.doc_url or decision.doc_url in ["nan", ""]:
                decision.resolution_text = "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π"
                decision.resolution_extracted_at = timezone.now()
                decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
                return decision
            
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ (SR_AI —Å—Ç–∏–ª—å)
            file_path = self.get_preloaded_document(str(decision.id))
            
            # –Ø–∫—â–æ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ —á–µ—Ä–∑—ñ, –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º
            if not file_path:
                unique_suffix = str(uuid.uuid4())[:8]
                file_path = self.download_document(decision.doc_url, f"{decision.id}_{unique_suffix}")
            
            if file_path:
                # –°—Ç–≤–æ—Ä—é—î–º–æ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è –¥–ª—è —Ñ–∞–π–ª—É (thread safety)
                with self.lock_for_locks:
                    if file_path not in self.file_locks:
                        self.file_locks[file_path] = threading.Lock()
                
                # –í–∏—Ç—è–≥—É—î–º–æ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—É —á–∞—Å—Ç–∏–Ω—É –∑ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è–º
                with self.file_locks[file_path]:
                    resolution_text = self.extract_resolution_text(file_path, "")
                    decision.resolution_text = resolution_text
                    decision.resolution_extracted_at = timezone.now()
                    
                    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ç—Ä–∏–≥–µ—Ä–Ω—ñ —Å–ª–æ–≤–∞ –ø—ñ—Å–ª—è –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
                    if resolution_text and not resolution_text.startswith("–ù–µ –≤–¥–∞–ª–æ—Å—è") and not resolution_text.startswith("–ü–æ–º–∏–ª–∫–∞"):
                        self.analyze_triggers(decision)
                
                # –í–∏–¥–∞–ª—è—î–º–æ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏
                with self.lock_for_locks:
                    if file_path in self.file_locks:
                        del self.file_locks[file_path]
                        
                # –í–∏–¥–∞–ª—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª (–æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø–∞–º"—è—Ç—ñ)
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                except:
                    pass
                        
            else:
                decision.resolution_text = "–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç"
                decision.resolution_extracted_at = timezone.now()
            
            decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
            return decision
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ–∫—Ä–∞—â–µ–Ω—ñ–π –æ–±—Ä–æ–±—Ü—ñ —Ä—ñ—à–µ–Ω–Ω—è {decision.id}: {e}")
            decision.resolution_text = f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"
            decision.resolution_extracted_at = timezone.now()
            decision.save(update_fields=[
                "resolution_text", "resolution_extracted_at", "has_trigger_words", "trigger_words_found", 
                "trigger_types", "is_critical_decision"
            ])
            return decision
    
    def extract_resolutions_batch(self, limit=None):
        """
        –í–∏—Ç—è–≥—É—î —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è —Ä—ñ—à–µ–Ω—å –±–µ–∑ —Ç–µ–∫—Å—Ç—É (–±–∞—Ç—á–∞–º–∏)
        """
        if limit is None:
            limit = self.batch_size
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä—ñ—à–µ–Ω–Ω—è –±–µ–∑ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É (NULL –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ)
        decisions_to_process = TrackedCourtDecision.objects.filter(
            doc_url__isnull=False
        ).filter(
            models.Q(resolution_text__isnull=True) | models.Q(resolution_text__exact="")
        ).exclude(
            doc_url__exact=""
        ).exclude(
            doc_url__exact="nan"
        ).order_by("-found_at")[:limit]
        
        if not decisions_to_process:
            return {
                "success": True,
                "processed": 0,
                "message": "–ù–µ–º–∞—î —Ä—ñ—à–µ–Ω—å –¥–ª—è –æ–±—Ä–æ–±–∫–∏"
            }
        
        print(f"–ü–æ—á–∞—Ç–æ–∫ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –¥–ª—è {len(decisions_to_process)} —Ä—ñ—à–µ–Ω—å...")
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        self.start_preloading(decisions_to_process)
        
        # üöÄ –°–¢–í–û–†–Æ–Ñ–ú–û –ë–Ü–õ–¨–®–Ü –ë–ê–¢–ß–Ü –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–á –®–í–ò–î–ö–û–î–Ü–á (SR_AI –ø—ñ–¥—Ö—ñ–¥)
        sub_batch_size = getattr(settings, "RESOLUTION_SUB_BATCH_SIZE", 200)  # –ö–†–ò–¢–ò–ß–ù–û: –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 200
        batches = [decisions_to_process[i:i+sub_batch_size] for i in range(0, len(decisions_to_process), sub_batch_size)]
        
        total_processed = 0
        total_decisions = len(decisions_to_process)
        success_count = 0
        
        print(f"–†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(batches)} –±–∞—Ç—á—ñ–≤ –ø–æ {sub_batch_size} —Ä—ñ—à–µ–Ω—å –º–∞–∫—Å–∏–º—É–º")
        
        try:
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω –±–∞—Ç—á –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ (SR_AI —Å—Ç–∏–ª—å)
            for batch_index, batch in enumerate(batches):
                print(f"–û–±—Ä–æ–±–∫–∞ –±–∞—Ç—á—É {batch_index+1}/{len(batches)}...")
                
                # üöÄ –ë–Ü–õ–¨–®–Ü –ú–Ü–ù–Ü-–ë–ê–¢–ß–Ü –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø –ü–û–¢–û–ö–Ü–í
                mini_batch_size = getattr(settings, "RESOLUTION_MINI_BATCH_SIZE", 75)  # –ö–†–ò–¢–ò–ß–ù–û: –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 75
                mini_batches = [batch[i:i+mini_batch_size] for i in range(0, len(batch), mini_batch_size)]
                
                for mini_batch in mini_batches:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ThreadPoolExecutor –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–æ—Ç–æ–∫—ñ–≤
                    with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ—à–µ–Ω–Ω—è
                        future_to_decision = {
                            executor.submit(self.process_single_decision_enhanced, decision): decision
                            for decision in mini_batch
                        }
                        
                        # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ –º—ñ—Ä—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                        for future in concurrent.futures.as_completed(future_to_decision):
                            try:
                                processed_decision = future.result()
                                # –í–ò–ü–†–ê–í–õ–ï–ù–ò–ô –∫—Ä–∏—Ç–µ—Ä—ñ–π —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ - –≤–∏–∫–ª—é—á–∞—î–º–æ —Ç–∞–∫–æ–∂ "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"
                                if (processed_decision and processed_decision.resolution_text and 
                                    not processed_decision.resolution_text.startswith("–ù–µ –≤–¥–∞–ª–æ—Å—è") and
                                    not processed_decision.resolution_text.startswith("–ü–æ–º–∏–ª–∫–∞") and
                                    processed_decision.resolution_text != "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞" and
                                    processed_decision.resolution_text != "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π"):
                                    success_count += 1
                                total_processed += 1
                                
                                # –ü–æ–∫–∞–∑—É—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å
                                if total_processed % 10 == 0 or total_processed == total_decisions:
                                    print(f"–ü—Ä–æ–≥—Ä–µ—Å: {total_processed}/{total_decisions} "
                                          f"({total_processed / total_decisions * 100:.1f}%), "
                                          f"—É—Å–ø—ñ—à–Ω–æ: {success_count}")
                                
                            except Exception as e:
                                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ä—ñ—à–µ–Ω–Ω—è: {e}")
                                total_processed += 1
                
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –±–∞—Ç—á {batch_index+1}/{len(batches)}. "
                      f"–ó–∞–≥–∞–ª—å–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å: {total_processed}/{total_decisions} "
                      f"({total_processed / total_decisions * 100:.1f}%)")
        
        finally:
            # –ó—É–ø–∏–Ω—è—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            self.stop_preloading()
        
        print(f"–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –∑–∞–≤–µ—Ä—à–µ–Ω–æ. "
              f"–û–±—Ä–æ–±–ª–µ–Ω–æ: {total_processed}, –£—Å–ø—ñ—à–Ω–æ: {success_count}")
        
        return {
            "success": True,
            "processed": total_processed,
            "successful": success_count,
            "failed": total_processed - success_count
        }
    
    def extract_resolutions_for_case(self, case_id, limit=None):
        """
        –í–∏—Ç—è–≥—É—î —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó —Å–ø—Ä–∞–≤–∏
        """
        from django.db import models
        
        if limit is None:
            limit = self.batch_size
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä—ñ—à–µ–Ω–Ω—è –±–µ–∑ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó —Å–ø—Ä–∞–≤–∏
        decisions_to_process = TrackedCourtDecision.objects.filter(
            tracked_case_id=case_id,
            doc_url__isnull=False
        ).filter(
            models.Q(resolution_text__isnull=True) | models.Q(resolution_text__exact="")
        ).exclude(
            doc_url__exact=""
        ).exclude(
            doc_url__exact="nan"
        ).order_by("-found_at")[:limit]
        
        if not decisions_to_process:
            return {
                "success": True,
                "processed": 0,
                "successful": 0,
                "failed": 0
            }
        
        decisions_list = list(decisions_to_process)
        print(f"–ü–æ—á–∞—Ç–æ–∫ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –¥–ª—è {len(decisions_list)} —Ä—ñ—à–µ–Ω—å —Å–ø—Ä–∞–≤–∏ {case_id}...")
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        self.start_preloading(decisions_list)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –±–∞—Ç—á—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ (SR_AI –ø—ñ–¥—Ö—ñ–¥)
        sub_batch_size = getattr(settings, "RESOLUTION_SUB_BATCH_SIZE", 25)
        batches = [decisions_list[i:i+sub_batch_size] for i in range(0, len(decisions_list), sub_batch_size)]
        
        total_processed = 0
        success_count = 0
        
        print(f"–†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(batches)} –±–∞—Ç—á—ñ–≤ –ø–æ {sub_batch_size} —Ä—ñ—à–µ–Ω—å –º–∞–∫—Å–∏–º—É–º")
        
        try:
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω –±–∞—Ç—á –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ
            for batch_index, batch in enumerate(batches):
                print(f"–û–±—Ä–æ–±–∫–∞ –±–∞—Ç—á—É {batch_index+1}/{len(batches)}...")
                
                # üöÄ –ë–Ü–õ–¨–®–Ü –ú–Ü–ù–Ü-–ë–ê–¢–ß–Ü –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø –ü–û–¢–û–ö–Ü–í
                mini_batch_size = getattr(settings, "RESOLUTION_MINI_BATCH_SIZE", 75)  # –ö–†–ò–¢–ò–ß–ù–û: –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 75
                mini_batches = [batch[i:i+mini_batch_size] for i in range(0, len(batch), mini_batch_size)]
                
                for mini_batch in mini_batches:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ThreadPoolExecutor –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–æ—Ç–æ–∫—ñ–≤
                    with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ—à–µ–Ω–Ω—è
                        future_to_decision = {
                            executor.submit(self.process_single_decision_enhanced, decision): decision
                            for decision in mini_batch
                        }
                        
                        # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ –º—ñ—Ä—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                        for future in concurrent.futures.as_completed(future_to_decision):
                            try:
                                processed_decision = future.result()
                                # –í–ò–ü–†–ê–í–õ–ï–ù–ò–ô –∫—Ä–∏—Ç–µ—Ä—ñ–π —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ - –≤–∏–∫–ª—é—á–∞—î–º–æ —Ç–∞–∫–æ–∂ "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"
                                if (processed_decision and processed_decision.resolution_text and 
                                    not processed_decision.resolution_text.startswith("–ù–µ –≤–¥–∞–ª–æ—Å—è") and
                                    not processed_decision.resolution_text.startswith("–ü–æ–º–∏–ª–∫–∞") and
                                    processed_decision.resolution_text != "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞" and
                                    processed_decision.resolution_text != "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π"):
                                    success_count += 1
                                total_processed += 1
                                
                                # –ü–æ–∫–∞–∑—É—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å
                                if total_processed % 5 == 0 or total_processed == len(decisions_list):
                                    print(f"–ü—Ä–æ–≥—Ä–µ—Å: {total_processed}/{len(decisions_list)} "
                                          f"({total_processed / len(decisions_list) * 100:.1f}%), "
                                          f"—É—Å–ø—ñ—à–Ω–æ: {success_count}")
                                
                            except Exception as e:
                                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ä—ñ—à–µ–Ω–Ω—è: {e}")
                                total_processed += 1
                
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –±–∞—Ç—á {batch_index+1}/{len(batches)}. "
                      f"–ó–∞–≥–∞–ª—å–Ω–∏–π –ø—Ä–æ–≥—Ä–µ—Å: {total_processed}/{len(decisions_list)} "
                      f"({total_processed / len(decisions_list) * 100:.1f}%)")
                
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—ñ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –¥–ª—è —Å–ø—Ä–∞–≤–∏ {case_id}: {e}")
            return {
                "success": False,
                "error": str(e),
                "processed": total_processed,
                "successful": success_count,
                "failed": total_processed - success_count
            }
        finally:
            # –ó—É–ø–∏–Ω—è—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            self.stop_preloading()
        
        print(f"–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –¥–ª—è —Å–ø—Ä–∞–≤–∏ {case_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. "
              f"–û–±—Ä–æ–±–ª–µ–Ω–æ: {total_processed}, –£—Å–ø—ñ—à–Ω–æ: {success_count}")
        
        return {
            "success": True,
            "processed": total_processed,
            "successful": success_count,
            "failed": total_processed - success_count
        }
    
    def extract_resolutions_batch_custom(self, decisions_list, progress_callback=None):
        """
        –í–∏—Ç—è–≥—É—î —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∞–Ω–æ–≥–æ —Å–ø–∏—Å–∫—É —Ä—ñ—à–µ–Ω—å –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—É
        """        
        if not decisions_list:
            return {
                "success": True,
                "processed": 0,
                "successful": 0,
                "failed": 0
            }
        
        print(f"–ü–æ—á–∞—Ç–æ–∫ —à–≤–∏–¥–∫–æ–≥–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –¥–ª—è {len(decisions_list)} —Ä—ñ—à–µ–Ω—å...")
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        self.start_preloading(decisions_list)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –±–∞—Ç—á—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ (SR_AI –ø—ñ–¥—Ö—ñ–¥)
        sub_batch_size = getattr(settings, "RESOLUTION_SUB_BATCH_SIZE", 25)
        batches = [decisions_list[i:i+sub_batch_size] for i in range(0, len(decisions_list), sub_batch_size)]
        
        total_processed = 0
        success_count = 0
        
        print(f"–†–æ–∑–¥—ñ–ª–µ–Ω–æ –Ω–∞ {len(batches)} –±–∞—Ç—á—ñ–≤ –ø–æ {sub_batch_size} —Ä—ñ—à–µ–Ω—å –º–∞–∫—Å–∏–º—É–º")
        
        try:
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω –±–∞—Ç—á –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ
            for batch_index, batch in enumerate(batches):
                # üöÄ –ë–Ü–õ–¨–®–Ü –ú–Ü–ù–Ü-–ë–ê–¢–ß–Ü –î–õ–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø –ü–û–¢–û–ö–Ü–í
                mini_batch_size = getattr(settings, "RESOLUTION_MINI_BATCH_SIZE", 75)  # –ö–†–ò–¢–ò–ß–ù–û: –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–æ 75
                mini_batches = [batch[i:i+mini_batch_size] for i in range(0, len(batch), mini_batch_size)]
                
                for mini_batch in mini_batches:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ThreadPoolExecutor –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–æ—Ç–æ–∫—ñ–≤
                    with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ—à–µ–Ω–Ω—è
                        future_to_decision = {
                            executor.submit(self.process_single_decision_enhanced, decision): decision
                            for decision in mini_batch
                        }
                        
                        # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ –º—ñ—Ä—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                        for future in concurrent.futures.as_completed(future_to_decision):
                            try:
                                processed_decision = future.result()
                                # –í–ò–ü–†–ê–í–õ–ï–ù–ò–ô –∫—Ä–∏—Ç–µ—Ä—ñ–π —É—Å–ø—ñ—à–Ω–æ—Å—Ç—ñ - –≤–∏–∫–ª—é—á–∞—î–º–æ —Ç–∞–∫–æ–∂ "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"
                                if (processed_decision and processed_decision.resolution_text and 
                                    not processed_decision.resolution_text.startswith("–ù–µ –≤–¥–∞–ª–æ—Å—è") and
                                    not processed_decision.resolution_text.startswith("–ü–æ–º–∏–ª–∫–∞") and
                                    processed_decision.resolution_text != "–†–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞" and
                                    processed_decision.resolution_text != "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π"):
                                    success_count += 1
                                total_processed += 1
                                
                                # –í–∏–∫–ª–∏–∫–∞—î–º–æ callback –¥–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É –∫–æ–∂–Ω—ñ 100 —Ä—ñ—à–µ–Ω—å
                                if progress_callback and total_processed % 100 == 0:
                                    progress_callback(total_processed, len(decisions_list), success_count)
                                
                            except Exception as e:
                                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ä—ñ—à–µ–Ω–Ω—è: {e}")
                                total_processed += 1
                
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —à–≤–∏–¥–∫–æ–º—É –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—ñ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω: {e}")
            return {
                "success": False,
                "error": str(e),
                "processed": total_processed,
                "successful": success_count,
                "failed": total_processed - success_count
            }
        finally:
            # –ó—É–ø–∏–Ω—è—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            self.stop_preloading()
            
            # –§—ñ–Ω–∞–ª—å–Ω–∏–π –≤–∏–∫–ª–∏–∫ callback
            if progress_callback:
                progress_callback(total_processed, len(decisions_list), success_count)
        
        return {
            "success": True,
            "processed": total_processed,
            "successful": success_count,
            "failed": total_processed - success_count
        }
    
    def extract_resolutions_continuous(self):
        """
        –ë–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω
        """
        print("–ó–∞–ø—É—Å–∫ –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ–≥–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω...")
        
        while True:
            try:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î —Ä—ñ—à–µ–Ω–Ω—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏
                pending_count = TrackedCourtDecision.objects.filter(
                    resolution_text__isnull=True,
                    doc_url__isnull=False
                ).exclude(
                    doc_url__exact=""
                ).exclude(
                    doc_url__exact="nan"
                ).count()
                
                if pending_count == 0:
                    print("–í—Å—ñ —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –≤–∏—Ç—è–≥–Ω—É—Ç–æ. –û—á—ñ–∫—É–≤–∞–Ω–Ω—è –Ω–æ–≤–∏—Ö —Ä—ñ—à–µ–Ω—å...")
                    time.sleep(60)  # –û—á—ñ–∫—É—î–º–æ 1 —Ö–≤–∏–ª–∏–Ω—É
                    continue
                
                print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {pending_count} —Ä—ñ—à–µ–Ω—å –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω")
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ –±–∞—Ç—á
                result = self.extract_resolutions_batch(self.batch_size)
                
                if result["processed"] == 0:
                    print("–ù–µ–º–∞—î —Ä—ñ—à–µ–Ω—å –¥–ª—è –æ–±—Ä–æ–±–∫–∏. –û—á—ñ–∫—É–≤–∞–Ω–Ω—è...")
                    time.sleep(30)
                else:
                    print(f"–û–±—Ä–æ–±–ª–µ–Ω–æ {result["processed"]} —Ä—ñ—à–µ–Ω—å, "
                          f"—É—Å–ø—ñ—à–Ω–æ –≤–∏—Ç—è–≥–Ω—É—Ç–æ {result["successful"]} —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω")
                
                # –ù–µ–≤–µ–ª–∏–∫–∞ –ø–∞—É–∑–∞ –º—ñ–∂ –±–∞—Ç—á–∞–º–∏
                time.sleep(5)
                
            except KeyboardInterrupt:
                print("–ó—É–ø–∏–Ω–∫–∞ –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ–≥–æ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑–∞ –∑–∞–ø–∏—Ç–æ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞")
                break
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤ –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ–º—É –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—ñ: {e}")
                print(f"–ü–æ–º–∏–ª–∫–∞ –≤ –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–æ–º—É –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—ñ: {e}")
                time.sleep(10)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ—é —Å–ø—Ä–æ–±–æ—é

    def analyze_triggers(self, decision):
        """
        –ê–Ω–∞–ª—ñ–∑—É—î —Ç—Ä–∏–≥–µ—Ä–Ω—ñ —Å–ª–æ–≤–∞ —É —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω—ñ–π —á–∞—Å—Ç–∏–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è
        """
        try:
            from bankruptcy.trigger_words import has_trigger_words
            
            if not decision.resolution_text:
                return
                
            analysis = has_trigger_words(decision.resolution_text)
            
            # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–Ω–∞–ª—ñ–∑—É
            decision.has_trigger_words = analysis["has_triggers"]
            decision.trigger_words_found = analysis["found_triggers"]
            decision.trigger_types = analysis["trigger_types"]
            decision.is_critical_decision = analysis["is_critical"]
            
            # –õ–æ–≥—É—î–º–æ –∑–Ω–∞—Ö—ñ–¥–∫–∏ —Ç—Ä–∏–≥–µ—Ä—ñ–≤
            if analysis["has_triggers"]:
                self.logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ —Ç—Ä–∏–≥–µ—Ä–∏ –≤ —Ä—ñ—à–µ–Ω–Ω—ñ {decision.id}: {analysis["found_triggers"]}")
                
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É —Ç—Ä–∏–≥–µ—Ä—ñ–≤ –¥–ª—è —Ä—ñ—à–µ–Ω–Ω—è {decision.id}: {e}")
    
    def extract_resolutions_incremental(self, limit=None):
        """
        –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω - —Ç—ñ–ª—å–∫–∏ –¥–ª—è –Ω–æ–≤–∏—Ö —Ä—ñ—à–µ–Ω—å
        """
        if limit is None:
            limit = self.batch_size
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ä—ñ—à–µ–Ω–Ω—è –ë–ï–ó —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É (—ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
        decisions_to_process = TrackedCourtDecision.objects.filter(
            models.Q(resolution_text__isnull=True) | models.Q(resolution_text__exact="")
        ).filter(
            doc_url__isnull=False
        ).exclude(
            doc_url__exact=""
        ).exclude(
            doc_url__exact="nan"
        ).order_by("-found_at")[:limit]
        
        if not decisions_to_process:
            return {
                "success": True,
                "processed": 0,
                "successful": 0,
                "failed": 0,
                "message": "–í—Å—ñ —Ä—ñ—à–µ–Ω–Ω—è –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω—ñ (—ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º)"
            }
        
        print(f"–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–ª—è {len(decisions_to_process)} –Ω–æ–≤–∏—Ö —Ä—ñ—à–µ–Ω—å...")
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç–æ–π –∂–µ –ø—ñ–¥—Ö—ñ–¥ —â–æ —ñ –≤ –∑–≤–∏—á–∞–π–Ω–æ–º—É –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—ñ
        return self.extract_resolutions_for_list(decisions_to_process)
    
    def should_use_incremental_mode(self):
        """
        –ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º
        """
        # –Ø–∫—â–æ –º–µ–Ω—à–µ 10% —Ä—ñ—à–µ–Ω—å –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –æ–±—Ä–æ–±–∫–∏ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º
        total_decisions = TrackedCourtDecision.objects.filter(
            doc_url__isnull=False
        ).exclude(
            doc_url__exact=""
        ).exclude(
            doc_url__exact="nan"
        ).count()
        
        pending_decisions = TrackedCourtDecision.objects.filter(
            models.Q(resolution_text__isnull=True) | models.Q(resolution_text__exact="")
        ).filter(
            doc_url__isnull=False
        ).exclude(
            doc_url__exact=""
        ).exclude(
            doc_url__exact="nan"
        ).count()
        
        if total_decisions == 0:
            return False
            
        pending_percentage = (pending_decisions / total_decisions) * 100
        
        # –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º, —è–∫—â–æ –º–µ–Ω—à–µ 10% –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –æ–±—Ä–æ–±–∫–∏
        return pending_percentage < 10.0


# –£—Ç–∏–ª—ñ—Ç–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ –∫–æ–º–∞–Ω–¥–∞—Ö —Ç–∞ views
def extract_resolutions_fast(limit=None):
    """
    –®–≤–∏–¥–∫–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω
    """
    extractor = FastResolutionExtractor()
    return extractor.extract_resolutions_batch(limit)


def start_continuous_extraction():
    """
    –ó–∞–ø—É—Å–∫–∞—î –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–µ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω
    """
    extractor = FastResolutionExtractor()
    extractor.extract_resolutions_continuous()


def get_extraction_statistics():
    """
    –û—Ç—Ä–∏–º—É—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑–æ–ª—é—Ç–∏–≤–Ω–∏—Ö —á–∞—Å—Ç–∏–Ω –∑ —Ç—Ä–∏–≥–µ—Ä–∞–º–∏
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –º–µ–Ω–µ–¥–∂–µ—Ä –∑"—î–¥–Ω–∞–Ω—å –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ—ó —Ä–æ–±–æ—Ç–∏
    """
    try:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–µ–Ω–µ–¥–∂–µ—Ä –∑"—î–¥–Ω–∞–Ω—å –¥–ª—è –±–µ–∑–ø–µ—á–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤
        from bankruptcy.utils.connection_manager import safe_db_connection
        
        with safe_db_connection() as connection:
            total_decisions = TrackedCourtDecision.objects.count()
            extracted_decisions = TrackedCourtDecision.objects.filter(
                resolution_text__isnull=False
            ).exclude(resolution_text__exact="").count()
            
            pending_decisions = TrackedCourtDecision.objects.filter(
                resolution_text__isnull=True,
                doc_url__isnull=False
            ).exclude(
                doc_url__exact=""
            ).exclude(
                doc_url__exact="nan"
            ).count()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç—Ä–∏–≥–µ—Ä—ñ–≤
            decisions_with_triggers = TrackedCourtDecision.objects.filter(
                has_trigger_words=True
            ).count()
            
            critical_decisions = TrackedCourtDecision.objects.filter(
                is_critical_decision=True
            ).count()
            
            resolution_triggers = TrackedCourtDecision.objects.filter(
                trigger_types__contains=["resolution"]
            ).count()
    except Exception as e:
        # –Ø–∫—â–æ –ø–æ–º–∏–ª–∫–∞ –∑"—î–¥–Ω–∞–Ω–Ω—è - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –±–∞–∑–æ–≤—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger = logging.getLogger(__name__)
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è: {e}")
        return {
            "total_decisions": 0,
            "extracted_decisions": 0,
            "pending_decisions": 0,
            "extraction_percentage": 0,
            "decisions_with_triggers": 0,
            "critical_decisions": 0,
            "resolution_triggers": 0,
            "trigger_percentage": 0,
            "error": str(e)
        }
    
    return {
        "total_decisions": total_decisions,
        "extracted_decisions": extracted_decisions,
        "pending_decisions": pending_decisions,
        "extraction_percentage": (extracted_decisions / total_decisions * 100) if total_decisions > 0 else 0,
        "decisions_with_triggers": decisions_with_triggers,
        "critical_decisions": critical_decisions,
        "resolution_triggers": resolution_triggers,
        "trigger_percentage": (decisions_with_triggers / extracted_decisions * 100) if extracted_decisions > 0 else 0
    }